{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recommender Systems 2024/25\n",
    "\n",
    "### Practice 9 - Deep Learning Models\n",
    "\n",
    "## The basics of Deep Learning: Multi-Layer Perceptron \n",
    "\n",
    "*Deep Learning* is a branch of Machine Learning research whose name is associated to many different meanings. With *Machine Learning*, we model a problem using data points that are often represented by means of multiple **features** of our design. In *Deep Learning* scenarios, instead, the \"machine\" often receives input data that received very little pre-processing, and the deep learner extracts the relevant features to solve the problem by itself. The following are some *Deep Learning*-based approaches to Recommendation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Movielens10M: Verifying data consistency...\n",
      "Movielens10M: Verifying data consistency... Passed!\n",
      "DataReader: current dataset is: Movielens10M\n",
      "\tNumber of items: 10681\n",
      "\tNumber of users: 69878\n",
      "\tNumber of interactions in URM_all: 10000054\n",
      "\tValue range in URM_all: 0.50-5.00\n",
      "\tInteraction density: 1.34E-02\n",
      "\tInteractions per user:\n",
      "\t\t Min: 2.00E+01\n",
      "\t\t Avg: 1.43E+02\n",
      "\t\t Max: 7.36E+03\n",
      "\tInteractions per item:\n",
      "\t\t Min: 0.00E+00\n",
      "\t\t Avg: 9.36E+02\n",
      "\t\t Max: 3.49E+04\n",
      "\tGini Index: 0.57\n",
      "\n",
      "\tICM name: ICM_tags, Value range: 1.00 / 69.00, Num features: 10106, feature occurrences: 106820, density 9.90E-04\n",
      "\tICM name: ICM_genres, Value range: 1.00 / 1.00, Num features: 20, feature occurrences: 21564, density 1.01E-01\n",
      "\tICM name: ICM_all, Value range: 1.00 / 69.00, Num features: 10126, feature occurrences: 128384, density 1.19E-03\n",
      "\tICM name: ICM_year, Value range: 1.92E+03 / 2.01E+03, Num features: 1, feature occurrences: 10681, density 1.00E+00\n",
      "\n",
      "\n",
      "Warning: 79 (0.11 %) of 69878 users have no sampled items\n",
      "Warning: 224 (0.32 %) of 69878 users have no sampled items\n"
     ]
    }
   ],
   "source": [
    "from Data_manager.split_functions.split_train_validation_random_holdout import split_train_in_two_percentage_global_sample\n",
    "from Data_manager.Movielens.Movielens10MReader import Movielens10MReader\n",
    "\n",
    "data_reader = Movielens10MReader()\n",
    "data_loaded = data_reader.load_data()\n",
    "\n",
    "URM_all = data_loaded.get_URM_all()\n",
    "\n",
    "URM_train_val, URM_test = split_train_in_two_percentage_global_sample(URM_all, 0.8)\n",
    "URM_train, URM_val = split_train_in_two_percentage_global_sample(URM_train_val, 0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EvaluatorHoldout: Ignoring 79 ( 0.1%) Users that have less than 1 test interactions\n",
      "EvaluatorHoldout: Ignoring 224 ( 0.3%) Users that have less than 1 test interactions\n"
     ]
    }
   ],
   "source": [
    "# Training and testing\n",
    "from Evaluation.Evaluator import EvaluatorHoldout\n",
    "\n",
    "evaluator_test = EvaluatorHoldout(URM_test, [10])\n",
    "evaluator_validation = EvaluatorHoldout(URM_val, [10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most *Deep Learning* techniques are **neural networks** of sorts. You may think Machine Learning is a \"young\" field of research, because its greatest breakthroughs are relatively recent, but its roots grow a bit further back in time: the concept of *Perceptron* as a function estimator was introduced by McCulloch and Pitts in 1943, and simulated for the first time by Rosenblatt in 1958! Neural networks, in their basic **Multi-Layer Perceptron** implementation, are nothing short than networks of densely interconnected *Perceptrons* (hence the name)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "if torch.backends.mps.is_available(): # if torch.cuda.is_available() if you use NVIDIA GPUs\n",
    "    device = torch.device(\"mps\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's build a simple Multi-Layer Perceptron in PyTorch to understand how it works. We will train and test it over the simple Iris Dataset (see also Practice 11)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load iris dataset\n",
    "iris = load_iris()\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "\n",
    "# split into train and test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# create a custom dataset class\n",
    "class IrisDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        self.X = torch.tensor(X, dtype=torch.float32)\n",
    "        self.y = torch.tensor(y, dtype=torch.long)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.y[idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our simple implementation will have 4 layers: one input layer, one output layer, and two hidden layers. In theory, three layers are enough to build a universal estimator (given that the hidden layer amounts for infinite perceptrons)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a custom nn.Module class\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(4, 16) # Input (4) -> hidden layer 1 (16)\n",
    "        self.fc2 = nn.Linear(16, 32) # hidden layer 1 (16) -> hidden layer 2 (32)\n",
    "        self.fc3 = nn.Linear(32, 3) # hidden layer 2 (32) -> output (3)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output layer has 3 neurons, as the Iris classification problem has 3 classes. Notice how we implement the model's \"architecture\", i.e., its layer structure, in the `__init__()` method, while the `forward()` method is used to define how layers interact with one another (by means of **activation functions**). Let's now fit and test the model on the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, loss: 1.113\n",
      "Epoch 2, loss: 1.090\n",
      "Epoch 3, loss: 1.076\n",
      "Epoch 4, loss: 1.059\n",
      "Epoch 5, loss: 1.058\n",
      "Epoch 6, loss: 1.041\n",
      "Epoch 7, loss: 1.033\n",
      "Epoch 8, loss: 1.026\n",
      "Epoch 9, loss: 1.022\n",
      "Epoch 10, loss: 1.007\n",
      "Epoch 11, loss: 0.999\n",
      "Epoch 12, loss: 0.990\n",
      "Epoch 13, loss: 0.982\n",
      "Epoch 14, loss: 0.975\n",
      "Epoch 15, loss: 0.962\n",
      "Epoch 16, loss: 0.953\n",
      "Epoch 17, loss: 0.941\n",
      "Epoch 18, loss: 0.935\n",
      "Epoch 19, loss: 0.919\n",
      "Epoch 20, loss: 0.913\n",
      "Epoch 21, loss: 0.897\n",
      "Epoch 22, loss: 0.883\n",
      "Epoch 23, loss: 0.877\n",
      "Epoch 24, loss: 0.859\n",
      "Epoch 25, loss: 0.850\n",
      "Epoch 26, loss: 0.832\n",
      "Epoch 27, loss: 0.822\n",
      "Epoch 28, loss: 0.810\n",
      "Epoch 29, loss: 0.795\n",
      "Epoch 30, loss: 0.783\n",
      "Epoch 31, loss: 0.769\n",
      "Epoch 32, loss: 0.758\n",
      "Epoch 33, loss: 0.744\n",
      "Epoch 34, loss: 0.733\n",
      "Epoch 35, loss: 0.710\n",
      "Epoch 36, loss: 0.704\n",
      "Epoch 37, loss: 0.686\n",
      "Epoch 38, loss: 0.675\n",
      "Epoch 39, loss: 0.668\n",
      "Epoch 40, loss: 0.658\n",
      "Epoch 41, loss: 0.640\n",
      "Epoch 42, loss: 0.632\n",
      "Epoch 43, loss: 0.619\n",
      "Epoch 44, loss: 0.609\n",
      "Epoch 45, loss: 0.595\n",
      "Epoch 46, loss: 0.592\n",
      "Epoch 47, loss: 0.583\n",
      "Epoch 48, loss: 0.569\n",
      "Epoch 49, loss: 0.556\n",
      "Epoch 50, loss: 0.555\n",
      "Epoch 51, loss: 0.547\n",
      "Epoch 52, loss: 0.539\n",
      "Epoch 53, loss: 0.528\n",
      "Epoch 54, loss: 0.523\n",
      "Epoch 55, loss: 0.517\n",
      "Epoch 56, loss: 0.506\n",
      "Epoch 57, loss: 0.507\n",
      "Epoch 58, loss: 0.496\n",
      "Epoch 59, loss: 0.497\n",
      "Epoch 60, loss: 0.492\n",
      "Epoch 61, loss: 0.483\n",
      "Epoch 62, loss: 0.475\n",
      "Epoch 63, loss: 0.474\n",
      "Epoch 64, loss: 0.479\n",
      "Epoch 65, loss: 0.459\n",
      "Epoch 66, loss: 0.458\n",
      "Epoch 67, loss: 0.459\n",
      "Epoch 68, loss: 0.451\n",
      "Epoch 69, loss: 0.444\n",
      "Epoch 70, loss: 0.442\n",
      "Epoch 71, loss: 0.436\n",
      "Epoch 72, loss: 0.431\n",
      "Epoch 73, loss: 0.430\n",
      "Epoch 74, loss: 0.436\n",
      "Epoch 75, loss: 0.426\n",
      "Epoch 76, loss: 0.421\n",
      "Epoch 77, loss: 0.413\n",
      "Epoch 78, loss: 0.408\n",
      "Epoch 79, loss: 0.412\n",
      "Epoch 80, loss: 0.399\n",
      "Epoch 81, loss: 0.401\n",
      "Epoch 82, loss: 0.391\n",
      "Epoch 83, loss: 0.388\n",
      "Epoch 84, loss: 0.389\n",
      "Epoch 85, loss: 0.384\n",
      "Epoch 86, loss: 0.387\n",
      "Epoch 87, loss: 0.375\n",
      "Epoch 88, loss: 0.375\n",
      "Epoch 89, loss: 0.371\n",
      "Epoch 90, loss: 0.369\n",
      "Epoch 91, loss: 0.371\n",
      "Epoch 92, loss: 0.360\n",
      "Epoch 93, loss: 0.353\n",
      "Epoch 94, loss: 0.357\n",
      "Epoch 95, loss: 0.356\n",
      "Epoch 96, loss: 0.351\n",
      "Epoch 97, loss: 0.344\n",
      "Epoch 98, loss: 0.339\n",
      "Epoch 99, loss: 0.340\n",
      "Epoch 100, loss: 0.336\n",
      "Test loss: 0.330, Accuracy: 96.67\n"
     ]
    }
   ],
   "source": [
    "# create a data loader and model\n",
    "dataset = IrisDataset(X_train, y_train)\n",
    "data_loader = torch.utils.data.DataLoader(dataset, batch_size=32, shuffle=True)\n",
    "model = MLP()\n",
    "\n",
    "# define a loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01)\n",
    "\n",
    "# train the model\n",
    "for epoch in range(100):\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(data_loader, 0):\n",
    "        inputs, labels = data\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "    print('Epoch %d, loss: %.3f' % (epoch+1, running_loss/(i+1)))\n",
    "\n",
    "# evaluate the model\n",
    "model.eval()\n",
    "test_loss = 0\n",
    "correct = 0\n",
    "with torch.no_grad():\n",
    "    for data in data_loader:\n",
    "        inputs, labels = data\n",
    "        outputs = model(inputs)\n",
    "        test_loss += criterion(outputs, labels).item()\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "accuracy = correct / len(dataset)\n",
    "print('Test loss: {:.3f}, Accuracy: {:.2f}'.format(test_loss/(len(data_loader)), accuracy*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the cell above, we define an **optimization strategy** (SGD), a **loss function** (Cross Entropy Loss) and a **training loop** that goes on for 100 epochs. We will need to do the same for every Deep Learning model we want to create."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unsurprisingly, our Multi-Layer Perceptron is very accurate! After all, the Iris problem is very simple for Machine Learning models.\n",
    "\n",
    "Let's now define a framework to build Deep Learning Recommender Systems. The following are our ingredients:\n",
    "- `__init__()` function that defines model architecture\n",
    "- data sampling strategy to generate batches of data over which models can be trained\n",
    "- `forward()` method to define layer-layer dynamics\n",
    "- `fit()` method to integrate architecture, sampling and `forward()` into a cohesive training schema and optimize the loss function\n",
    "- `_compute_item_score()` method to compute rating predictions. The mother class `BaseRecommender`, when this method is implemented, will correctly handle the `recommend()` part."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.sparse as sp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Recommenders.BaseRecommender import BaseRecommender\n",
    "\n",
    "class DeepLearningRecommender(nn.Module, BaseRecommender):\n",
    "\n",
    "    def __init__(self, URM_train, verbose=True):\n",
    "        super().__init__()\n",
    "        BaseRecommender.__init__(self, URM_train, verbose)\n",
    "        self.device = torch.device(\"mps\") if torch.backends.mps.is_available() else torch.device(\"cpu\")\n",
    "\n",
    "    def _data_generator(self, batch_size, num_negatives=3, num_items=None):\n",
    "        user_input, item_input, labels = [], [], []\n",
    "        dok_train = URM_train.todok() # <- Dictionary representation of a sparse matrix: allows us to check existing interactions as key-value pairs\n",
    "        if num_items is None : num_items = self.URM_train.shape[1]\n",
    "\n",
    "        self.batch_counter = 0\n",
    "        start = self.batch_counter\n",
    "        stop = min(self.batch_counter + batch_size, len(dok_train.keys()))\n",
    "        for (u,i) in dok_train[start:stop].keys():\n",
    "            # positive interaction\n",
    "            user_input.append(u)\n",
    "            item_input.append(i)\n",
    "            labels.append(1) # <- (Implicit ratings)\n",
    "            # negative interactions\n",
    "            for t in range(num_negatives): # <- num_negatives is a hyperparameter\n",
    "                # randomly select an interaction; check if negative\n",
    "                j = np.random.randint(num_items)\n",
    "                while (u,j) in dok_train:\n",
    "                    j = np.random.randint(num_items)\n",
    "                user_input.append(u)\n",
    "                item_input.append(j)\n",
    "                labels.append(0)\n",
    "        self.batch_counter += 1\n",
    "        \n",
    "        user_input = torch.tensor(user_input, dtype=torch.int32, device=self.device)\n",
    "        item_input = torch.tensor(item_input, dtype=torch.int32, device=self.device)\n",
    "        labels = torch.tensor(labels, dtype=torch.int32, device=self.device)\n",
    "        labels = labels.reshape((labels.shape[0],1))\n",
    "        yield user_input, item_input, labels\n",
    "    \n",
    "    def forward(self, user_input, item_input=None):\n",
    "        raise NotImplementedError(\"Forward function not implemented.\")\n",
    "\n",
    "    def fit(self, epochs=30, batch_size=1024, learning_rate=0.0001):\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=learning_rate) # <- The optimizer can be (additionally) considered as a hyperparameter\n",
    "        for i in range(epochs):\n",
    "            for user_input, item_input, labels in self._data_generator(batch_size):\n",
    "                optimizer.zero_grad()\n",
    "                predictions = self.forward(user_input, item_input)\n",
    "                loss = torch.nn.BCELoss().to(self.device) # <- The loss function can be (additionally) considered as a hyperparameter\n",
    "                loss = loss(predictions, labels.float())\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "            self._print(\"Epoch {} finished. Loss: {}\".format(i, loss.item()))\n",
    "\n",
    "    def _compute_item_score(self, user_id_array, items_to_compute=None):\n",
    "        step = user_id_array.shape[0]\n",
    "        \n",
    "        if items_to_compute is None:\n",
    "            items_to_compute = np.arange(self.URM_train.shape[1], dtype=np.int32)\n",
    "        \n",
    "        predictions = np.empty((step,items_to_compute.shape[0]))\n",
    "        for item in items_to_compute:\n",
    "            with torch.no_grad():\n",
    "                predictions[:, item] = self.forward(\n",
    "                    torch.tensor(user_id_array),\n",
    "                    torch.tensor(\n",
    "                        np.ones(step, dtype=np.int32) * item)\n",
    "                    ).cpu().detach().numpy().ravel()\n",
    "        return predictions\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AutoEncoders"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Denoising Autoencoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first Deep Learning model we're going to study is a Denoising Autoencoder.\n",
    "\n",
    "*Autoencoders* are a family of Deep Learning algorithms often used for *Representation Learning*. They can be divided in two components: an *encoder*, which computes a compressed representation of the input data, and a *decoder*, which is tasked with reconstructing the original input data given a representation.\n",
    "\n",
    "A *Denoising Autoencoder* adds some noise to the input before passing it to the encoder. Since the final label for the decoder is the original (not noisy) input, training such an algorithm will return a model that is able of filtering noise out.\n",
    "\n",
    "In Recommendation, we make no use of a \"perfect\" Autoencoder: in fact, the interactions it will make up to recommend are nothing but the **reconstruction errors** the decoder will (inevitably) make. We count on the fact that such errors are driven by a representation learned over collaborative signals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DenoisingAutoencoder(DeepLearningRecommender):\n",
    "\n",
    "    RECOMMENDER_NAME = \"\"\"DENOISING_AUTOENCODER\"\"\"\n",
    "    def __init__(self, URM_train, encoding_dim=69, noise_p=0.01, verbose=True):\n",
    "        super().__init__(URM_train, verbose)\n",
    "        self.noise_p = noise_p\n",
    "        num_items = URM_train.shape[1]\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(num_items, 420),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(420, encoding_dim)\n",
    "        )\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(encoding_dim, 420),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(420, num_items)\n",
    "        )\n",
    "        self.to(self.device)\n",
    "    \n",
    "    # override: both input and label are batches of user profiles\n",
    "    def _data_generator(self, batch_size):\n",
    "        row_idx = np.arange(self.URM_train.shape[0])\n",
    "        for start in range(0, len(row_idx), batch_size):\n",
    "            end = min(len(row_idx), start + batch_size)\n",
    "            user_input = torch.tensor(self.URM_train[row_idx[start:end],:].toarray(), dtype=torch.float32, device=self.device)\n",
    "            labels = user_input\n",
    "            yield user_input, _, labels\n",
    "\n",
    "    def forward(self, user_input, item_input=None):\n",
    "        # assert(item_input == None, \"Item input not needed\")\n",
    "        noisy_input = self._add_noise(user_input)\n",
    "        encoded = self.encoder(noisy_input)\n",
    "        reconstructed = self.decoder(encoded)\n",
    "        return reconstructed\n",
    "\n",
    "    # override: evaluator passes user profile ids as inputs, we need the\n",
    "    #           full profiles for the forward function to work properly\n",
    "    def _compute_item_score(self, user_id_array, items_to_compute=None):\n",
    "        user_profiles = self.URM_train[user_id_array, :]\n",
    "\n",
    "        if items_to_compute is not None:\n",
    "            mask = np.zeros(self.URM.shape[1], dtype=np.int32)\n",
    "            mask[items_to_compute] = 1\n",
    "            user_profiles = user_profiles[:, mask]\n",
    "\n",
    "        with torch.no_grad():\n",
    "            predictions = self.forward(torch.tensor(user_profiles.toarray(), dtype=torch.float32, device=self.device))\n",
    "\n",
    "        return predictions.cpu().detach().numpy()\n",
    "\n",
    "    def _add_noise(self, x):\n",
    "        zeros_mask = np.random.choice([False,True], size=x.shape, p=[1-self.noise_p, self.noise_p])\n",
    "        ones_mask = np.random.choice([False,True], size=x.shape, p=[1-self.noise_p, self.noise_p])\n",
    "        x[zeros_mask] = 0\n",
    "        x[ones_mask] = 1\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As the class we created inherits from `DeepLearningRecommender`, which, in turn, inherits from `BaseRecommender`, we can now evaluate its performance using our framework's classic evaluation procedure!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DENOISING_AUTOENCODER: URM Detected 55 ( 0.5%) items with no interactions.\n",
      "DENOISING_AUTOENCODER: Epoch 0 finished. Loss: 0.11099840700626373\n",
      "DENOISING_AUTOENCODER: Epoch 1 finished. Loss: 0.08202937245368958\n",
      "DENOISING_AUTOENCODER: Epoch 2 finished. Loss: 0.1918686032295227\n",
      "DENOISING_AUTOENCODER: Epoch 3 finished. Loss: 0.19098085165023804\n",
      "DENOISING_AUTOENCODER: Epoch 4 finished. Loss: 0.1933378130197525\n",
      "DENOISING_AUTOENCODER: Epoch 5 finished. Loss: 0.1907622516155243\n",
      "DENOISING_AUTOENCODER: Epoch 6 finished. Loss: 0.19027526676654816\n",
      "DENOISING_AUTOENCODER: Epoch 7 finished. Loss: 0.19064201414585114\n",
      "DENOISING_AUTOENCODER: Epoch 8 finished. Loss: 0.1934140920639038\n",
      "DENOISING_AUTOENCODER: Epoch 9 finished. Loss: 0.1913139373064041\n",
      "DENOISING_AUTOENCODER: Epoch 10 finished. Loss: 0.19287773966789246\n",
      "DENOISING_AUTOENCODER: Epoch 11 finished. Loss: 0.19070233404636383\n",
      "DENOISING_AUTOENCODER: Epoch 12 finished. Loss: 0.19218724966049194\n",
      "DENOISING_AUTOENCODER: Epoch 13 finished. Loss: 0.19340915977954865\n",
      "DENOISING_AUTOENCODER: Epoch 14 finished. Loss: 0.19355693459510803\n",
      "DENOISING_AUTOENCODER: Epoch 15 finished. Loss: 0.1909925639629364\n",
      "DENOISING_AUTOENCODER: Epoch 16 finished. Loss: 0.194160595536232\n",
      "DENOISING_AUTOENCODER: Epoch 17 finished. Loss: 0.19187721610069275\n",
      "DENOISING_AUTOENCODER: Epoch 18 finished. Loss: 0.1932610422372818\n",
      "DENOISING_AUTOENCODER: Epoch 19 finished. Loss: 0.19160327315330505\n",
      "DENOISING_AUTOENCODER: Epoch 20 finished. Loss: 0.19017551839351654\n",
      "DENOISING_AUTOENCODER: Epoch 21 finished. Loss: 0.1923200786113739\n",
      "DENOISING_AUTOENCODER: Epoch 22 finished. Loss: 0.1918942779302597\n",
      "DENOISING_AUTOENCODER: Epoch 23 finished. Loss: 0.19183415174484253\n",
      "DENOISING_AUTOENCODER: Epoch 24 finished. Loss: 0.19058920443058014\n",
      "DENOISING_AUTOENCODER: Epoch 25 finished. Loss: 0.19293411076068878\n",
      "DENOISING_AUTOENCODER: Epoch 26 finished. Loss: 0.1915360391139984\n",
      "DENOISING_AUTOENCODER: Epoch 27 finished. Loss: 0.18947145342826843\n",
      "DENOISING_AUTOENCODER: Epoch 28 finished. Loss: 0.1945098489522934\n",
      "DENOISING_AUTOENCODER: Epoch 29 finished. Loss: 0.19349579513072968\n",
      "DENOISING_AUTOENCODER: Epoch 30 finished. Loss: 0.20735694468021393\n",
      "DENOISING_AUTOENCODER: Epoch 31 finished. Loss: 0.19482629001140594\n",
      "DENOISING_AUTOENCODER: Epoch 32 finished. Loss: 0.1864548623561859\n",
      "DENOISING_AUTOENCODER: Epoch 33 finished. Loss: 0.1867639720439911\n",
      "DENOISING_AUTOENCODER: Epoch 34 finished. Loss: 0.18622836470603943\n",
      "DENOISING_AUTOENCODER: Epoch 35 finished. Loss: 0.18652980029582977\n",
      "DENOISING_AUTOENCODER: Epoch 36 finished. Loss: 0.1862889528274536\n",
      "DENOISING_AUTOENCODER: Epoch 37 finished. Loss: 0.1864297091960907\n",
      "DENOISING_AUTOENCODER: Epoch 38 finished. Loss: 0.18628448247909546\n",
      "DENOISING_AUTOENCODER: Epoch 39 finished. Loss: 0.18697641789913177\n",
      "DENOISING_AUTOENCODER: Epoch 40 finished. Loss: 0.18620680272579193\n",
      "DENOISING_AUTOENCODER: Epoch 41 finished. Loss: 0.18659047782421112\n",
      "DENOISING_AUTOENCODER: Epoch 42 finished. Loss: 0.1870543509721756\n",
      "DENOISING_AUTOENCODER: Epoch 43 finished. Loss: 0.18669307231903076\n",
      "DENOISING_AUTOENCODER: Epoch 44 finished. Loss: 0.18644611537456512\n",
      "DENOISING_AUTOENCODER: Epoch 45 finished. Loss: 0.186771422624588\n",
      "DENOISING_AUTOENCODER: Epoch 46 finished. Loss: 0.18635421991348267\n",
      "DENOISING_AUTOENCODER: Epoch 47 finished. Loss: 0.18670973181724548\n",
      "DENOISING_AUTOENCODER: Epoch 48 finished. Loss: 0.18664537370204926\n",
      "DENOISING_AUTOENCODER: Epoch 49 finished. Loss: 0.18655793368816376\n",
      "DENOISING_AUTOENCODER: Epoch 50 finished. Loss: 0.1862456351518631\n",
      "DENOISING_AUTOENCODER: Epoch 51 finished. Loss: 0.18631097674369812\n",
      "DENOISING_AUTOENCODER: Epoch 52 finished. Loss: 0.18660151958465576\n",
      "DENOISING_AUTOENCODER: Epoch 53 finished. Loss: 0.18660815060138702\n",
      "DENOISING_AUTOENCODER: Epoch 54 finished. Loss: 0.18636253476142883\n",
      "DENOISING_AUTOENCODER: Epoch 55 finished. Loss: 0.18665434420108795\n",
      "DENOISING_AUTOENCODER: Epoch 56 finished. Loss: 0.18659839034080505\n",
      "DENOISING_AUTOENCODER: Epoch 57 finished. Loss: 0.1867145299911499\n",
      "DENOISING_AUTOENCODER: Epoch 58 finished. Loss: 0.1862356960773468\n",
      "DENOISING_AUTOENCODER: Epoch 59 finished. Loss: 0.18666118383407593\n",
      "DENOISING_AUTOENCODER: Epoch 60 finished. Loss: 0.1866481453180313\n",
      "DENOISING_AUTOENCODER: Epoch 61 finished. Loss: 0.18672919273376465\n",
      "DENOISING_AUTOENCODER: Epoch 62 finished. Loss: 0.18684060871601105\n",
      "DENOISING_AUTOENCODER: Epoch 63 finished. Loss: 0.18632841110229492\n",
      "DENOISING_AUTOENCODER: Epoch 64 finished. Loss: 0.18709401786327362\n",
      "DENOISING_AUTOENCODER: Epoch 65 finished. Loss: 0.1864825338125229\n",
      "DENOISING_AUTOENCODER: Epoch 66 finished. Loss: 0.18651360273361206\n",
      "DENOISING_AUTOENCODER: Epoch 67 finished. Loss: 0.1865207999944687\n",
      "DENOISING_AUTOENCODER: Epoch 68 finished. Loss: 0.18519143760204315\n",
      "DENOISING_AUTOENCODER: Epoch 69 finished. Loss: 0.18435759842395782\n",
      "DENOISING_AUTOENCODER: Epoch 70 finished. Loss: 0.1845252513885498\n",
      "DENOISING_AUTOENCODER: Epoch 71 finished. Loss: 0.1840657740831375\n",
      "DENOISING_AUTOENCODER: Epoch 72 finished. Loss: 0.18407070636749268\n",
      "DENOISING_AUTOENCODER: Epoch 73 finished. Loss: 0.18437600135803223\n",
      "DENOISING_AUTOENCODER: Epoch 74 finished. Loss: 0.18433739244937897\n",
      "DENOISING_AUTOENCODER: Epoch 75 finished. Loss: 0.18467611074447632\n",
      "DENOISING_AUTOENCODER: Epoch 76 finished. Loss: 0.18376362323760986\n",
      "DENOISING_AUTOENCODER: Epoch 77 finished. Loss: 0.1841767579317093\n",
      "DENOISING_AUTOENCODER: Epoch 78 finished. Loss: 0.18415461480617523\n",
      "DENOISING_AUTOENCODER: Epoch 79 finished. Loss: 0.18426349759101868\n",
      "DENOISING_AUTOENCODER: Epoch 80 finished. Loss: 0.18444861471652985\n",
      "DENOISING_AUTOENCODER: Epoch 81 finished. Loss: 0.18440374732017517\n",
      "DENOISING_AUTOENCODER: Epoch 82 finished. Loss: 0.18422046303749084\n",
      "DENOISING_AUTOENCODER: Epoch 83 finished. Loss: 0.1841306984424591\n",
      "DENOISING_AUTOENCODER: Epoch 84 finished. Loss: 0.18403755128383636\n",
      "DENOISING_AUTOENCODER: Epoch 85 finished. Loss: 0.184320867061615\n",
      "DENOISING_AUTOENCODER: Epoch 86 finished. Loss: 0.18425628542900085\n",
      "DENOISING_AUTOENCODER: Epoch 87 finished. Loss: 0.1841275542974472\n",
      "DENOISING_AUTOENCODER: Epoch 88 finished. Loss: 0.18443666398525238\n",
      "DENOISING_AUTOENCODER: Epoch 89 finished. Loss: 0.18436439335346222\n",
      "DENOISING_AUTOENCODER: Epoch 90 finished. Loss: 0.1845153123140335\n",
      "DENOISING_AUTOENCODER: Epoch 91 finished. Loss: 0.1841539442539215\n",
      "DENOISING_AUTOENCODER: Epoch 92 finished. Loss: 0.18431885540485382\n",
      "DENOISING_AUTOENCODER: Epoch 93 finished. Loss: 0.18467062711715698\n",
      "DENOISING_AUTOENCODER: Epoch 94 finished. Loss: 0.18434785306453705\n",
      "DENOISING_AUTOENCODER: Epoch 95 finished. Loss: 0.18410129845142365\n",
      "DENOISING_AUTOENCODER: Epoch 96 finished. Loss: 0.18454435467720032\n",
      "DENOISING_AUTOENCODER: Epoch 97 finished. Loss: 0.18403936922550201\n",
      "DENOISING_AUTOENCODER: Epoch 98 finished. Loss: 0.1844714730978012\n",
      "DENOISING_AUTOENCODER: Epoch 99 finished. Loss: 0.18424956500530243\n",
      "EvaluatorHoldout: Processed 69799 (100.0%) in 41.17 sec. Users per second: 1695\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PRECISION</th>\n",
       "      <th>PRECISION_RECALL_MIN_DEN</th>\n",
       "      <th>RECALL</th>\n",
       "      <th>MAP</th>\n",
       "      <th>MAP_MIN_DEN</th>\n",
       "      <th>MRR</th>\n",
       "      <th>NDCG</th>\n",
       "      <th>F1</th>\n",
       "      <th>HIT_RATE</th>\n",
       "      <th>ARHR_ALL_HITS</th>\n",
       "      <th>...</th>\n",
       "      <th>COVERAGE_USER</th>\n",
       "      <th>COVERAGE_USER_HIT</th>\n",
       "      <th>USERS_IN_GT</th>\n",
       "      <th>DIVERSITY_GINI</th>\n",
       "      <th>SHANNON_ENTROPY</th>\n",
       "      <th>RATIO_DIVERSITY_HERFINDAHL</th>\n",
       "      <th>RATIO_DIVERSITY_GINI</th>\n",
       "      <th>RATIO_SHANNON_ENTROPY</th>\n",
       "      <th>RATIO_AVERAGE_POPULARITY</th>\n",
       "      <th>RATIO_NOVELTY</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cutoff</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.053489</td>\n",
       "      <td>0.060789</td>\n",
       "      <td>0.033699</td>\n",
       "      <td>0.031674</td>\n",
       "      <td>0.03566</td>\n",
       "      <td>0.231949</td>\n",
       "      <td>0.069474</td>\n",
       "      <td>0.041348</td>\n",
       "      <td>0.388602</td>\n",
       "      <td>0.271416</td>\n",
       "      <td>...</td>\n",
       "      <td>0.998869</td>\n",
       "      <td>0.388162</td>\n",
       "      <td>0.998869</td>\n",
       "      <td>0.001181</td>\n",
       "      <td>3.759496</td>\n",
       "      <td>0.922565</td>\n",
       "      <td>0.006071</td>\n",
       "      <td>0.331987</td>\n",
       "      <td>1.324892</td>\n",
       "      <td>0.131732</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       PRECISION PRECISION_RECALL_MIN_DEN    RECALL       MAP MAP_MIN_DEN  \\\n",
       "cutoff                                                                      \n",
       "10      0.053489                 0.060789  0.033699  0.031674     0.03566   \n",
       "\n",
       "             MRR      NDCG        F1  HIT_RATE ARHR_ALL_HITS  ...  \\\n",
       "cutoff                                                        ...   \n",
       "10      0.231949  0.069474  0.041348  0.388602      0.271416  ...   \n",
       "\n",
       "       COVERAGE_USER COVERAGE_USER_HIT USERS_IN_GT DIVERSITY_GINI  \\\n",
       "cutoff                                                              \n",
       "10          0.998869          0.388162    0.998869       0.001181   \n",
       "\n",
       "       SHANNON_ENTROPY RATIO_DIVERSITY_HERFINDAHL RATIO_DIVERSITY_GINI  \\\n",
       "cutoff                                                                   \n",
       "10            3.759496                   0.922565             0.006071   \n",
       "\n",
       "       RATIO_SHANNON_ENTROPY RATIO_AVERAGE_POPULARITY RATIO_NOVELTY  \n",
       "cutoff                                                               \n",
       "10                  0.331987                 1.324892      0.131732  \n",
       "\n",
       "[1 rows x 27 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "denoising_autoencoder = DenoisingAutoencoder(URM_train)\n",
    "\n",
    "denoising_autoencoder.fit(epochs=100, batch_size=1024, learning_rate=0.005)\n",
    "\n",
    "results_df, _ = evaluator_test.evaluateRecommender(denoising_autoencoder)\n",
    "\n",
    "results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### $EASE^R$\n",
    "\n",
    "An Autoencoder with no hidden layers used in Recommendation is equivalent to an **item-item similarity** based Recommender. $EASE^R$ is a closed form, similarity-based model built with such notion in mind, that's why we classify it as an Autoencoder. It's usually a very strong baseline and very fast to compute, but its memory consumption is a known issue.\n",
    "\n",
    "The algorithm is defined by the following formula: $$S^* = \\underset{S}{\\arg\\min} ||R - RS||_F + 2 \\vec{\\gamma} \\odot diag(S),$$ which develops into this solution: $$S^* = I_{|I|} - P \\cdot diagMat(\\vec{1} \\oslash diag(P)),$$ having $P = (R^T \\cdot R + \\lambda I_{|I|})^{-1}$.\n",
    "\n",
    "Below, we present its `fit` function, that defines the gist of the algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import normalize\n",
    "\n",
    "def fit(self, topK=None, l2_norm = 1e3, normalize_matrix = False):\n",
    "\n",
    "        if normalize_matrix:\n",
    "            # Normalize rows and then columns\n",
    "            self.URM_train = normalize(self.URM_train, norm='l2', axis=1)\n",
    "            self.URM_train = normalize(self.URM_train, norm='l2', axis=0)\n",
    "            self.URM_train = sp.csr_matrix(self.URM_train)\n",
    "\n",
    "\n",
    "        # Grahm matrix is X^t X, compute dot product\n",
    "        grahm_matrix = self.URM_train.T.dot(self.URM_train).toarray() # <- HUGE dense matrix!\n",
    "\n",
    "        diag_indices = np.diag_indices(grahm_matrix.shape[0])\n",
    "        grahm_matrix[diag_indices] += l2_norm\n",
    "\n",
    "        P = np.linalg.inv(grahm_matrix) # <- Matrix inversion is a HEAVY computation!\n",
    "\n",
    "        B = P / (-np.diag(P))\n",
    "\n",
    "        B[diag_indices] = 0.0 # <- avoid having identity matrix as a solution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$EASE^R$ is available in the `Recommenders` module, so you can use it by means of a simple import."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EASE_R_Recommender: URM Detected 55 ( 0.5%) items with no interactions.\n",
      "EASE_R_Recommender: Fitting model... \n",
      "EASE_R_Recommender: Fitting model... done in 16.10 sec\n",
      "EvaluatorHoldout: Processed 69799 (100.0%) in 21.77 sec. Users per second: 3205\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PRECISION</th>\n",
       "      <th>PRECISION_RECALL_MIN_DEN</th>\n",
       "      <th>RECALL</th>\n",
       "      <th>MAP</th>\n",
       "      <th>MAP_MIN_DEN</th>\n",
       "      <th>MRR</th>\n",
       "      <th>NDCG</th>\n",
       "      <th>F1</th>\n",
       "      <th>HIT_RATE</th>\n",
       "      <th>ARHR_ALL_HITS</th>\n",
       "      <th>...</th>\n",
       "      <th>COVERAGE_USER</th>\n",
       "      <th>COVERAGE_USER_HIT</th>\n",
       "      <th>USERS_IN_GT</th>\n",
       "      <th>DIVERSITY_GINI</th>\n",
       "      <th>SHANNON_ENTROPY</th>\n",
       "      <th>RATIO_DIVERSITY_HERFINDAHL</th>\n",
       "      <th>RATIO_DIVERSITY_GINI</th>\n",
       "      <th>RATIO_SHANNON_ENTROPY</th>\n",
       "      <th>RATIO_AVERAGE_POPULARITY</th>\n",
       "      <th>RATIO_NOVELTY</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cutoff</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.278086</td>\n",
       "      <td>0.323435</td>\n",
       "      <td>0.189679</td>\n",
       "      <td>0.165758</td>\n",
       "      <td>0.188332</td>\n",
       "      <td>0.534839</td>\n",
       "      <td>0.27962</td>\n",
       "      <td>0.225528</td>\n",
       "      <td>0.870356</td>\n",
       "      <td>0.919851</td>\n",
       "      <td>...</td>\n",
       "      <td>0.998869</td>\n",
       "      <td>0.869372</td>\n",
       "      <td>0.998869</td>\n",
       "      <td>0.025281</td>\n",
       "      <td>8.328613</td>\n",
       "      <td>0.99468</td>\n",
       "      <td>0.129904</td>\n",
       "      <td>0.735469</td>\n",
       "      <td>1.690481</td>\n",
       "      <td>0.091213</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       PRECISION PRECISION_RECALL_MIN_DEN    RECALL       MAP MAP_MIN_DEN  \\\n",
       "cutoff                                                                      \n",
       "10      0.278086                 0.323435  0.189679  0.165758    0.188332   \n",
       "\n",
       "             MRR     NDCG        F1  HIT_RATE ARHR_ALL_HITS  ...  \\\n",
       "cutoff                                                       ...   \n",
       "10      0.534839  0.27962  0.225528  0.870356      0.919851  ...   \n",
       "\n",
       "       COVERAGE_USER COVERAGE_USER_HIT USERS_IN_GT DIVERSITY_GINI  \\\n",
       "cutoff                                                              \n",
       "10          0.998869          0.869372    0.998869       0.025281   \n",
       "\n",
       "       SHANNON_ENTROPY RATIO_DIVERSITY_HERFINDAHL RATIO_DIVERSITY_GINI  \\\n",
       "cutoff                                                                   \n",
       "10            8.328613                    0.99468             0.129904   \n",
       "\n",
       "       RATIO_SHANNON_ENTROPY RATIO_AVERAGE_POPULARITY RATIO_NOVELTY  \n",
       "cutoff                                                               \n",
       "10                  0.735469                 1.690481      0.091213  \n",
       "\n",
       "[1 rows x 27 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from Recommenders.EASE_R.EASE_R_Recommender import EASE_R_Recommender\n",
    "\n",
    "model = EASE_R_Recommender(URM_train)\n",
    "\n",
    "model.fit() # <- hyperparams left to default value, obviously could (and should) be optimized\n",
    "\n",
    "results_df, _ = evaluator_test.evaluateRecommender(model)\n",
    "\n",
    "results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Two-Tower Models\n",
    "\n",
    "Two-tower neural recommenders are sort of an industry standard, nowadays. Being model-based, very fast at inference time and very versatile, they fit very well in \"Big Data\" contexts, where users and items are in the order of millions and content diversity would overwhelm anyone who tried to model the task's features by hand. Usually, they are used as a \"first filter\", selecting a large amount of recommendable items, which are subsequently sorted by a more refined re-ranker.\n",
    "\n",
    "Their basic architecture, as the name suggests, has two components (towers): one that processes user-related information and another for item-related information. Information could include their interaction profiles, some type of unstructured data or pretty much anything, really. After creating two representations of profile batches, they are merged and passed to a final set of layers, tasked with predicting ratings/ranking.\n",
    "\n",
    "In this session, we will see two different ways to implement a basic Two Tower model. The first type, reported below, has shallow towers and a deeper \"post-merge block\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variant 1:\n",
    "# 1. Make 2 embeddings of equal dimensions and concatenate\n",
    "# 2. Couple of Dense layers\n",
    "# 3. Obtain prediction (single score)\n",
    "class TwoTowerRecommender_type1(DeepLearningRecommender):\n",
    "    \n",
    "    RECOMMENDER_NAME = \"\"\"TWO_TOWER_1\"\"\"\n",
    "    \n",
    "    def __init__(self, URM_train, num_users, num_items, layers=[10], reg_layers=[0], verbose = True):\n",
    "        super().__init__(URM_train, verbose)\n",
    "        self.mlp_embedding_user = nn.Embedding(num_users, int(layers[0]/2), device=self.device) # <- The input for each tower will be a learned latent representation,\n",
    "        self.mlp_embedding_item = nn.Embedding(num_items, int(layers[0]/2), device=self.device) # <- sort of like what we have seen for Matrix Factorization.\n",
    "\n",
    "        self.mlp_layers = nn.ModuleList([\n",
    "            nn.Linear(layers[i-1], layers[i], bias=True, device=self.device) for i in range(1, len(layers))\n",
    "            ])\n",
    "        for i, layer in enumerate(self.mlp_layers):\n",
    "            nn.init.normal_(layer.weight)\n",
    "            layer.bias.data.zero_()\n",
    "            layer.weight_decay = reg_layers[i]\n",
    "\n",
    "        self.prediction_layer = nn.Linear(layers[-1], 1, bias=True, device=self.device)\n",
    "        nn.init.uniform_(self.prediction_layer.weight)\n",
    "        self.prediction_layer.bias.data.zero_()\n",
    "        self.to(self.device)\n",
    "\n",
    "    def forward(self, user_input, item_input):\n",
    "        mlp_user_latent = self.mlp_embedding_user(user_input.long().to(self.device)) # <- shallow tower: we just extract the embedding corresponding to the profiles\n",
    "        mlp_item_latent = self.mlp_embedding_item(item_input.long().to(self.device))\n",
    "        mlp_vector = torch.cat((mlp_user_latent, mlp_item_latent), dim=1) # <- Concatenate user and item embeddings\n",
    "        for layer in self.mlp_layers:\n",
    "            mlp_vector = torch.relu(layer(mlp_vector)) # <- MLP after-merge processing block\n",
    "\n",
    "        predict_vector = mlp_vector\n",
    "        prediction = torch.sigmoid(self.prediction_layer(predict_vector))\n",
    "        return prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The second type has deeper towers, and a simple sigmoid predictor as \"post-merge block\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variant 2:\n",
    "# 1. Couple of Dense layers process user/item profiles\n",
    "# 2. Merge and final Dense layer to obtain prediciton\n",
    "class TwoTowerRecommender_type2(DeepLearningRecommender):\n",
    "\n",
    "    RECOMMENDER_NAME = \"\"\"TWO_TOWER_2\"\"\"\n",
    "\n",
    "    def __init__(self, URM_train, num_users, num_items, layers=[10], reg_layers=[0], verbose = True):\n",
    "        super().__init__(URM_train, verbose)\n",
    "        layers[0] = int(layers[0]/2) # <- The first layer is split in two tower inputs at the beginning\n",
    "        self.mlp_embedding_user = nn.Embedding(num_users, layers[0], device=self.device)\n",
    "        self.mlp_embedding_item = nn.Embedding(num_items, layers[0], device=self.device) # <- It's possible to make the towers asymmetric! Mind the output dimension though\n",
    "\n",
    "        self.mlp_layers_tower1 = nn.ModuleList([ # <- First tower MLP\n",
    "            nn.Linear(\n",
    "                layers[i-1],\n",
    "                layers[i], bias=True, device=self.device\n",
    "                ) for i in range(1, len(layers))\n",
    "            ])\n",
    "        \n",
    "        self.mlp_layers_tower2 = nn.ModuleList([ # <- Second tower MLP\n",
    "            nn.Linear(\n",
    "                layers[i-1],\n",
    "                layers[i], bias=True, device=self.device\n",
    "                ) for i in range(1, len(layers))\n",
    "            ])\n",
    "        \n",
    "        for i, layer in enumerate(self.mlp_layers_tower1):\n",
    "            nn.init.normal_(layer.weight)\n",
    "            layer.bias.data.zero_()\n",
    "            layer.weight_decay = reg_layers[i]\n",
    "\n",
    "        for i, layer in enumerate(self.mlp_layers_tower2):\n",
    "            nn.init.normal_(layer.weight)\n",
    "            layer.bias.data.zero_()\n",
    "            layer.weight_decay = reg_layers[i]\n",
    "\n",
    "        self.prediction_layer = nn.Linear(layers[-1], 1, bias=True, device=self.device) # <- shallow post-merge block: a simple linear layer with sigmoid activation\n",
    "        nn.init.uniform_(self.prediction_layer.weight)\n",
    "        self.prediction_layer.bias.data.zero_()\n",
    "        self.to(self.device)\n",
    "\n",
    "    def forward(self, user_input, item_input):\n",
    "        mlp_user_latent = self.mlp_embedding_user(user_input.long().to(self.device))\n",
    "        mlp_item_latent = self.mlp_embedding_item(item_input.long().to(self.device))\n",
    "\n",
    "        mlp_user_vector = mlp_user_latent\n",
    "        mlp_item_vector = mlp_item_latent\n",
    "\n",
    "        for layer in self.mlp_layers_tower1:\n",
    "            mlp_user_vector = torch.relu(layer(mlp_user_vector))\n",
    "\n",
    "        for layer in self.mlp_layers_tower2:\n",
    "            mlp_item_vector = torch.relu(layer(mlp_item_vector))\n",
    "\n",
    "        predict_vector = mlp_user_vector * mlp_item_vector # <- Merge the tensors via element-wise multiplication\n",
    "        prediction = torch.sigmoid(self.prediction_layer(predict_vector))\n",
    "        return prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Both classes inherit from `DeepLearningRecommender`, without overriding its `_data_generator()` and `fit()` methods. Given that `DeepLearningRecommender` inherits from `BaseRecommender`, we can now use the framework's evaluation functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TWO_TOWER_1: URM Detected 55 ( 0.5%) items with no interactions.\n",
      "TWO_TOWER_1: Epoch 0 finished. Loss: 0.8925771117210388\n",
      "TWO_TOWER_1: Epoch 1 finished. Loss: 0.854363203048706\n",
      "TWO_TOWER_1: Epoch 2 finished. Loss: 0.8213669061660767\n",
      "TWO_TOWER_1: Epoch 3 finished. Loss: 0.7946606874465942\n",
      "TWO_TOWER_1: Epoch 4 finished. Loss: 0.7702852487564087\n",
      "TWO_TOWER_1: Epoch 5 finished. Loss: 0.7511789202690125\n",
      "TWO_TOWER_1: Epoch 6 finished. Loss: 0.7346419095993042\n",
      "TWO_TOWER_1: Epoch 7 finished. Loss: 0.7209672331809998\n",
      "TWO_TOWER_1: Epoch 8 finished. Loss: 0.7092865705490112\n",
      "TWO_TOWER_1: Epoch 9 finished. Loss: 0.6997858285903931\n",
      "TWO_TOWER_1: Epoch 10 finished. Loss: 0.6920063495635986\n",
      "TWO_TOWER_1: Epoch 11 finished. Loss: 0.6848570704460144\n",
      "TWO_TOWER_1: Epoch 12 finished. Loss: 0.6792639493942261\n",
      "TWO_TOWER_1: Epoch 13 finished. Loss: 0.6744208335876465\n",
      "TWO_TOWER_1: Epoch 14 finished. Loss: 0.6698777675628662\n",
      "TWO_TOWER_1: Epoch 15 finished. Loss: 0.6660910844802856\n",
      "TWO_TOWER_1: Epoch 16 finished. Loss: 0.6626678705215454\n",
      "TWO_TOWER_1: Epoch 17 finished. Loss: 0.6596317887306213\n",
      "TWO_TOWER_1: Epoch 18 finished. Loss: 0.6568517088890076\n",
      "TWO_TOWER_1: Epoch 19 finished. Loss: 0.6541315913200378\n",
      "TWO_TOWER_1: Epoch 20 finished. Loss: 0.6518064737319946\n",
      "TWO_TOWER_1: Epoch 21 finished. Loss: 0.649534285068512\n",
      "TWO_TOWER_1: Epoch 22 finished. Loss: 0.6473745703697205\n",
      "TWO_TOWER_1: Epoch 23 finished. Loss: 0.6452846527099609\n",
      "TWO_TOWER_1: Epoch 24 finished. Loss: 0.6433776617050171\n",
      "TWO_TOWER_1: Epoch 25 finished. Loss: 0.6415148973464966\n",
      "TWO_TOWER_1: Epoch 26 finished. Loss: 0.6396859884262085\n",
      "TWO_TOWER_1: Epoch 27 finished. Loss: 0.6379331350326538\n",
      "TWO_TOWER_1: Epoch 28 finished. Loss: 0.6362065076828003\n",
      "TWO_TOWER_1: Epoch 29 finished. Loss: 0.6345400214195251\n",
      "TWO_TOWER_1: Epoch 30 finished. Loss: 0.6329081058502197\n",
      "TWO_TOWER_1: Epoch 31 finished. Loss: 0.6313539743423462\n",
      "TWO_TOWER_1: Epoch 32 finished. Loss: 0.6297924518585205\n",
      "TWO_TOWER_1: Epoch 33 finished. Loss: 0.6282877922058105\n",
      "TWO_TOWER_1: Epoch 34 finished. Loss: 0.6268064975738525\n",
      "TWO_TOWER_1: Epoch 35 finished. Loss: 0.6253597736358643\n",
      "TWO_TOWER_1: Epoch 36 finished. Loss: 0.6239325404167175\n",
      "TWO_TOWER_1: Epoch 37 finished. Loss: 0.6225607991218567\n",
      "TWO_TOWER_1: Epoch 38 finished. Loss: 0.6211804151535034\n",
      "TWO_TOWER_1: Epoch 39 finished. Loss: 0.6198474764823914\n",
      "TWO_TOWER_1: Epoch 40 finished. Loss: 0.6185450553894043\n",
      "TWO_TOWER_1: Epoch 41 finished. Loss: 0.6172512769699097\n",
      "TWO_TOWER_1: Epoch 42 finished. Loss: 0.615993320941925\n",
      "TWO_TOWER_1: Epoch 43 finished. Loss: 0.614749014377594\n",
      "TWO_TOWER_1: Epoch 44 finished. Loss: 0.6135457754135132\n",
      "TWO_TOWER_1: Epoch 45 finished. Loss: 0.6123452186584473\n",
      "TWO_TOWER_1: Epoch 46 finished. Loss: 0.6111840605735779\n",
      "TWO_TOWER_1: Epoch 47 finished. Loss: 0.610028862953186\n",
      "TWO_TOWER_1: Epoch 48 finished. Loss: 0.6089062690734863\n",
      "TWO_TOWER_1: Epoch 49 finished. Loss: 0.6078014969825745\n",
      "TWO_TOWER_1: Epoch 50 finished. Loss: 0.6067196726799011\n",
      "TWO_TOWER_1: Epoch 51 finished. Loss: 0.6056579947471619\n",
      "TWO_TOWER_1: Epoch 52 finished. Loss: 0.6046191453933716\n",
      "TWO_TOWER_1: Epoch 53 finished. Loss: 0.6035942435264587\n",
      "TWO_TOWER_1: Epoch 54 finished. Loss: 0.6025866866111755\n",
      "TWO_TOWER_1: Epoch 55 finished. Loss: 0.6016116142272949\n",
      "TWO_TOWER_1: Epoch 56 finished. Loss: 0.6006448268890381\n",
      "TWO_TOWER_1: Epoch 57 finished. Loss: 0.5996982455253601\n",
      "TWO_TOWER_1: Epoch 58 finished. Loss: 0.5987685322761536\n",
      "TWO_TOWER_1: Epoch 59 finished. Loss: 0.5978653430938721\n",
      "TWO_TOWER_1: Epoch 60 finished. Loss: 0.5969732999801636\n",
      "TWO_TOWER_1: Epoch 61 finished. Loss: 0.596096396446228\n",
      "TWO_TOWER_1: Epoch 62 finished. Loss: 0.595244288444519\n",
      "TWO_TOWER_1: Epoch 63 finished. Loss: 0.5944039225578308\n",
      "TWO_TOWER_1: Epoch 64 finished. Loss: 0.5935757756233215\n",
      "TWO_TOWER_1: Epoch 65 finished. Loss: 0.5927749872207642\n",
      "TWO_TOWER_1: Epoch 66 finished. Loss: 0.5919893383979797\n",
      "TWO_TOWER_1: Epoch 67 finished. Loss: 0.5912086963653564\n",
      "TWO_TOWER_1: Epoch 68 finished. Loss: 0.5904413461685181\n",
      "TWO_TOWER_1: Epoch 69 finished. Loss: 0.5897075533866882\n",
      "TWO_TOWER_1: Epoch 70 finished. Loss: 0.5889772176742554\n",
      "TWO_TOWER_1: Epoch 71 finished. Loss: 0.5882622003555298\n",
      "TWO_TOWER_1: Epoch 72 finished. Loss: 0.5875589847564697\n",
      "TWO_TOWER_1: Epoch 73 finished. Loss: 0.5868675708770752\n",
      "TWO_TOWER_1: Epoch 74 finished. Loss: 0.586205244064331\n",
      "TWO_TOWER_1: Epoch 75 finished. Loss: 0.5855419039726257\n",
      "TWO_TOWER_1: Epoch 76 finished. Loss: 0.5848952531814575\n",
      "TWO_TOWER_1: Epoch 77 finished. Loss: 0.5842588543891907\n",
      "TWO_TOWER_1: Epoch 78 finished. Loss: 0.5836372971534729\n",
      "TWO_TOWER_1: Epoch 79 finished. Loss: 0.5830258727073669\n",
      "TWO_TOWER_1: Epoch 80 finished. Loss: 0.5824100971221924\n",
      "TWO_TOWER_1: Epoch 81 finished. Loss: 0.5818375945091248\n",
      "TWO_TOWER_1: Epoch 82 finished. Loss: 0.581252932548523\n",
      "TWO_TOWER_1: Epoch 83 finished. Loss: 0.5807055830955505\n",
      "TWO_TOWER_1: Epoch 84 finished. Loss: 0.5801418423652649\n",
      "TWO_TOWER_1: Epoch 85 finished. Loss: 0.5795847177505493\n",
      "TWO_TOWER_1: Epoch 86 finished. Loss: 0.5790393352508545\n",
      "TWO_TOWER_1: Epoch 87 finished. Loss: 0.5785207748413086\n",
      "TWO_TOWER_1: Epoch 88 finished. Loss: 0.5780074000358582\n",
      "TWO_TOWER_1: Epoch 89 finished. Loss: 0.5774933099746704\n",
      "TWO_TOWER_1: Epoch 90 finished. Loss: 0.5769832134246826\n",
      "TWO_TOWER_1: Epoch 91 finished. Loss: 0.576486349105835\n",
      "TWO_TOWER_1: Epoch 92 finished. Loss: 0.5760015249252319\n",
      "TWO_TOWER_1: Epoch 93 finished. Loss: 0.5755062699317932\n",
      "TWO_TOWER_1: Epoch 94 finished. Loss: 0.5750057101249695\n",
      "TWO_TOWER_1: Epoch 95 finished. Loss: 0.5745560526847839\n",
      "TWO_TOWER_1: Epoch 96 finished. Loss: 0.5740910768508911\n",
      "TWO_TOWER_1: Epoch 97 finished. Loss: 0.5736083984375\n",
      "TWO_TOWER_1: Epoch 98 finished. Loss: 0.5731407999992371\n",
      "TWO_TOWER_1: Epoch 99 finished. Loss: 0.572668194770813\n",
      "EvaluatorHoldout: Processed 36000 (51.6%) in 5.13 min. Users per second: 117\n",
      "EvaluatorHoldout: Processed 69799 (100.0%) in 9.96 min. Users per second: 117\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PRECISION</th>\n",
       "      <th>PRECISION_RECALL_MIN_DEN</th>\n",
       "      <th>RECALL</th>\n",
       "      <th>MAP</th>\n",
       "      <th>MAP_MIN_DEN</th>\n",
       "      <th>MRR</th>\n",
       "      <th>NDCG</th>\n",
       "      <th>F1</th>\n",
       "      <th>HIT_RATE</th>\n",
       "      <th>ARHR_ALL_HITS</th>\n",
       "      <th>...</th>\n",
       "      <th>COVERAGE_USER</th>\n",
       "      <th>COVERAGE_USER_HIT</th>\n",
       "      <th>USERS_IN_GT</th>\n",
       "      <th>DIVERSITY_GINI</th>\n",
       "      <th>SHANNON_ENTROPY</th>\n",
       "      <th>RATIO_DIVERSITY_HERFINDAHL</th>\n",
       "      <th>RATIO_DIVERSITY_GINI</th>\n",
       "      <th>RATIO_SHANNON_ENTROPY</th>\n",
       "      <th>RATIO_AVERAGE_POPULARITY</th>\n",
       "      <th>RATIO_NOVELTY</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cutoff</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.022618</td>\n",
       "      <td>0.023836</td>\n",
       "      <td>0.008735</td>\n",
       "      <td>0.007052</td>\n",
       "      <td>0.00737</td>\n",
       "      <td>0.054136</td>\n",
       "      <td>0.013001</td>\n",
       "      <td>0.012602</td>\n",
       "      <td>0.180676</td>\n",
       "      <td>0.061509</td>\n",
       "      <td>...</td>\n",
       "      <td>0.998869</td>\n",
       "      <td>0.180472</td>\n",
       "      <td>0.998869</td>\n",
       "      <td>0.004583</td>\n",
       "      <td>5.465076</td>\n",
       "      <td>0.956677</td>\n",
       "      <td>0.023549</td>\n",
       "      <td>0.482601</td>\n",
       "      <td>0.659349</td>\n",
       "      <td>0.117162</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       PRECISION PRECISION_RECALL_MIN_DEN    RECALL       MAP MAP_MIN_DEN  \\\n",
       "cutoff                                                                      \n",
       "10      0.022618                 0.023836  0.008735  0.007052     0.00737   \n",
       "\n",
       "             MRR      NDCG        F1  HIT_RATE ARHR_ALL_HITS  ...  \\\n",
       "cutoff                                                        ...   \n",
       "10      0.054136  0.013001  0.012602  0.180676      0.061509  ...   \n",
       "\n",
       "       COVERAGE_USER COVERAGE_USER_HIT USERS_IN_GT DIVERSITY_GINI  \\\n",
       "cutoff                                                              \n",
       "10          0.998869          0.180472    0.998869       0.004583   \n",
       "\n",
       "       SHANNON_ENTROPY RATIO_DIVERSITY_HERFINDAHL RATIO_DIVERSITY_GINI  \\\n",
       "cutoff                                                                   \n",
       "10            5.465076                   0.956677             0.023549   \n",
       "\n",
       "       RATIO_SHANNON_ENTROPY RATIO_AVERAGE_POPULARITY RATIO_NOVELTY  \n",
       "cutoff                                                               \n",
       "10                  0.482601                 0.659349      0.117162  \n",
       "\n",
       "[1 rows x 27 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train and test type 1\n",
    "twotower_1 = TwoTowerRecommender_type1(URM_train, URM_train.shape[0], URM_train.shape[1], layers=[10,5,2,2], reg_layers=[0,0,0,0])\n",
    "\n",
    "twotower_1.fit(epochs=100, batch_size=1024, learning_rate=0.01)\n",
    "\n",
    "results_df, _ = evaluator_test.evaluateRecommender(twotower_1)\n",
    "\n",
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TWO_TOWER_2: URM Detected 55 ( 0.5%) items with no interactions.\n",
      "TWO_TOWER_2: Epoch 0 finished. Loss: 0.6931471824645996\n",
      "TWO_TOWER_2: Epoch 1 finished. Loss: 0.6906595826148987\n",
      "TWO_TOWER_2: Epoch 2 finished. Loss: 0.6881978511810303\n",
      "TWO_TOWER_2: Epoch 3 finished. Loss: 0.6857620477676392\n",
      "TWO_TOWER_2: Epoch 4 finished. Loss: 0.6833529472351074\n",
      "TWO_TOWER_2: Epoch 5 finished. Loss: 0.6809706687927246\n",
      "TWO_TOWER_2: Epoch 6 finished. Loss: 0.6786155700683594\n",
      "TWO_TOWER_2: Epoch 7 finished. Loss: 0.6762882471084595\n",
      "TWO_TOWER_2: Epoch 8 finished. Loss: 0.6739888191223145\n",
      "TWO_TOWER_2: Epoch 9 finished. Loss: 0.6717178225517273\n",
      "TWO_TOWER_2: Epoch 10 finished. Loss: 0.6694753170013428\n",
      "TWO_TOWER_2: Epoch 11 finished. Loss: 0.6672616600990295\n",
      "TWO_TOWER_2: Epoch 12 finished. Loss: 0.665077269077301\n",
      "TWO_TOWER_2: Epoch 13 finished. Loss: 0.662922203540802\n",
      "TWO_TOWER_2: Epoch 14 finished. Loss: 0.6607966423034668\n",
      "TWO_TOWER_2: Epoch 15 finished. Loss: 0.6587006449699402\n",
      "TWO_TOWER_2: Epoch 16 finished. Loss: 0.6566349267959595\n",
      "TWO_TOWER_2: Epoch 17 finished. Loss: 0.6545990705490112\n",
      "TWO_TOWER_2: Epoch 18 finished. Loss: 0.6525932550430298\n",
      "TWO_TOWER_2: Epoch 19 finished. Loss: 0.6506175994873047\n",
      "TWO_TOWER_2: Epoch 20 finished. Loss: 0.6486724019050598\n",
      "TWO_TOWER_2: Epoch 21 finished. Loss: 0.6467574238777161\n",
      "TWO_TOWER_2: Epoch 22 finished. Loss: 0.6448726654052734\n",
      "TWO_TOWER_2: Epoch 23 finished. Loss: 0.6430184245109558\n",
      "TWO_TOWER_2: Epoch 24 finished. Loss: 0.641194224357605\n",
      "TWO_TOWER_2: Epoch 25 finished. Loss: 0.6394004821777344\n",
      "TWO_TOWER_2: Epoch 26 finished. Loss: 0.6376367211341858\n",
      "TWO_TOWER_2: Epoch 27 finished. Loss: 0.6359031200408936\n",
      "TWO_TOWER_2: Epoch 28 finished. Loss: 0.6341994404792786\n",
      "TWO_TOWER_2: Epoch 29 finished. Loss: 0.6325254440307617\n",
      "TWO_TOWER_2: Epoch 30 finished. Loss: 0.6308811902999878\n",
      "TWO_TOWER_2: Epoch 31 finished. Loss: 0.6292664408683777\n",
      "TWO_TOWER_2: Epoch 32 finished. Loss: 0.6276810169219971\n",
      "TWO_TOWER_2: Epoch 33 finished. Loss: 0.6261245012283325\n",
      "TWO_TOWER_2: Epoch 34 finished. Loss: 0.6245969533920288\n",
      "TWO_TOWER_2: Epoch 35 finished. Loss: 0.6230982542037964\n",
      "TWO_TOWER_2: Epoch 36 finished. Loss: 0.6216278076171875\n",
      "TWO_TOWER_2: Epoch 37 finished. Loss: 0.6201854944229126\n",
      "TWO_TOWER_2: Epoch 38 finished. Loss: 0.6187711358070374\n",
      "TWO_TOWER_2: Epoch 39 finished. Loss: 0.6173842549324036\n",
      "TWO_TOWER_2: Epoch 40 finished. Loss: 0.6160248517990112\n",
      "TWO_TOWER_2: Epoch 41 finished. Loss: 0.6146923899650574\n",
      "TWO_TOWER_2: Epoch 42 finished. Loss: 0.613386869430542\n",
      "TWO_TOWER_2: Epoch 43 finished. Loss: 0.6121077537536621\n",
      "TWO_TOWER_2: Epoch 44 finished. Loss: 0.6108545660972595\n",
      "TWO_TOWER_2: Epoch 45 finished. Loss: 0.609627366065979\n",
      "TWO_TOWER_2: Epoch 46 finished. Loss: 0.608425498008728\n",
      "TWO_TOWER_2: Epoch 47 finished. Loss: 0.6072489023208618\n",
      "TWO_TOWER_2: Epoch 48 finished. Loss: 0.6060969829559326\n",
      "TWO_TOWER_2: Epoch 49 finished. Loss: 0.6049695611000061\n",
      "TWO_TOWER_2: Epoch 50 finished. Loss: 0.6038662791252136\n",
      "TWO_TOWER_2: Epoch 51 finished. Loss: 0.6027867197990417\n",
      "TWO_TOWER_2: Epoch 52 finished. Loss: 0.6017308235168457\n",
      "TWO_TOWER_2: Epoch 53 finished. Loss: 0.6006978154182434\n",
      "TWO_TOWER_2: Epoch 54 finished. Loss: 0.5996875762939453\n",
      "TWO_TOWER_2: Epoch 55 finished. Loss: 0.5986996293067932\n",
      "TWO_TOWER_2: Epoch 56 finished. Loss: 0.5977339148521423\n",
      "TWO_TOWER_2: Epoch 57 finished. Loss: 0.5967897176742554\n",
      "TWO_TOWER_2: Epoch 58 finished. Loss: 0.5958667993545532\n",
      "TWO_TOWER_2: Epoch 59 finished. Loss: 0.5949649810791016\n",
      "TWO_TOWER_2: Epoch 60 finished. Loss: 0.594083845615387\n",
      "TWO_TOWER_2: Epoch 61 finished. Loss: 0.5932227373123169\n",
      "TWO_TOWER_2: Epoch 62 finished. Loss: 0.5923816561698914\n",
      "TWO_TOWER_2: Epoch 63 finished. Loss: 0.5915601849555969\n",
      "TWO_TOWER_2: Epoch 64 finished. Loss: 0.5907579064369202\n",
      "TWO_TOWER_2: Epoch 65 finished. Loss: 0.5899747610092163\n",
      "TWO_TOWER_2: Epoch 66 finished. Loss: 0.5892099142074585\n",
      "TWO_TOWER_2: Epoch 67 finished. Loss: 0.5884631872177124\n",
      "TWO_TOWER_2: Epoch 68 finished. Loss: 0.5877345204353333\n",
      "TWO_TOWER_2: Epoch 69 finished. Loss: 0.5870231986045837\n",
      "TWO_TOWER_2: Epoch 70 finished. Loss: 0.5863292217254639\n",
      "TWO_TOWER_2: Epoch 71 finished. Loss: 0.5856522917747498\n",
      "TWO_TOWER_2: Epoch 72 finished. Loss: 0.5849917531013489\n",
      "TWO_TOWER_2: Epoch 73 finished. Loss: 0.5843473672866821\n",
      "TWO_TOWER_2: Epoch 74 finished. Loss: 0.5837189555168152\n",
      "TWO_TOWER_2: Epoch 75 finished. Loss: 0.583106279373169\n",
      "TWO_TOWER_2: Epoch 76 finished. Loss: 0.5825086832046509\n",
      "TWO_TOWER_2: Epoch 77 finished. Loss: 0.5819262266159058\n",
      "TWO_TOWER_2: Epoch 78 finished. Loss: 0.5813584923744202\n",
      "TWO_TOWER_2: Epoch 79 finished. Loss: 0.5808050036430359\n",
      "TWO_TOWER_2: Epoch 80 finished. Loss: 0.5802657604217529\n",
      "TWO_TOWER_2: Epoch 81 finished. Loss: 0.5797401666641235\n",
      "TWO_TOWER_2: Epoch 82 finished. Loss: 0.5792281031608582\n",
      "TWO_TOWER_2: Epoch 83 finished. Loss: 0.5787293314933777\n",
      "TWO_TOWER_2: Epoch 84 finished. Loss: 0.5782434344291687\n",
      "TWO_TOWER_2: Epoch 85 finished. Loss: 0.5777703523635864\n",
      "TWO_TOWER_2: Epoch 86 finished. Loss: 0.5773095488548279\n",
      "TWO_TOWER_2: Epoch 87 finished. Loss: 0.5768607258796692\n",
      "TWO_TOWER_2: Epoch 88 finished. Loss: 0.5764239430427551\n",
      "TWO_TOWER_2: Epoch 89 finished. Loss: 0.5759986639022827\n",
      "TWO_TOWER_2: Epoch 90 finished. Loss: 0.5755847692489624\n",
      "TWO_TOWER_2: Epoch 91 finished. Loss: 0.5751819610595703\n",
      "TWO_TOWER_2: Epoch 92 finished. Loss: 0.5747900605201721\n",
      "TWO_TOWER_2: Epoch 93 finished. Loss: 0.5744087100028992\n",
      "TWO_TOWER_2: Epoch 94 finished. Loss: 0.5740377306938171\n",
      "TWO_TOWER_2: Epoch 95 finished. Loss: 0.5736768841743469\n",
      "TWO_TOWER_2: Epoch 96 finished. Loss: 0.5733258724212646\n",
      "TWO_TOWER_2: Epoch 97 finished. Loss: 0.5729844570159912\n",
      "TWO_TOWER_2: Epoch 98 finished. Loss: 0.5726525187492371\n",
      "TWO_TOWER_2: Epoch 99 finished. Loss: 0.5723296999931335\n",
      "EvaluatorHoldout: Processed 30000 (43.0%) in 5.06 min. Users per second: 99\n",
      "EvaluatorHoldout: Processed 60000 (86.0%) in 10.11 min. Users per second: 99\n",
      "EvaluatorHoldout: Processed 69799 (100.0%) in 11.79 min. Users per second: 99\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PRECISION</th>\n",
       "      <th>PRECISION_RECALL_MIN_DEN</th>\n",
       "      <th>RECALL</th>\n",
       "      <th>MAP</th>\n",
       "      <th>MAP_MIN_DEN</th>\n",
       "      <th>MRR</th>\n",
       "      <th>NDCG</th>\n",
       "      <th>F1</th>\n",
       "      <th>HIT_RATE</th>\n",
       "      <th>ARHR_ALL_HITS</th>\n",
       "      <th>...</th>\n",
       "      <th>COVERAGE_USER</th>\n",
       "      <th>COVERAGE_USER_HIT</th>\n",
       "      <th>USERS_IN_GT</th>\n",
       "      <th>DIVERSITY_GINI</th>\n",
       "      <th>SHANNON_ENTROPY</th>\n",
       "      <th>RATIO_DIVERSITY_HERFINDAHL</th>\n",
       "      <th>RATIO_DIVERSITY_GINI</th>\n",
       "      <th>RATIO_SHANNON_ENTROPY</th>\n",
       "      <th>RATIO_AVERAGE_POPULARITY</th>\n",
       "      <th>RATIO_NOVELTY</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cutoff</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.000208</td>\n",
       "      <td>0.000209</td>\n",
       "      <td>0.000032</td>\n",
       "      <td>0.00007</td>\n",
       "      <td>0.000071</td>\n",
       "      <td>0.000617</td>\n",
       "      <td>0.000103</td>\n",
       "      <td>0.000056</td>\n",
       "      <td>0.001848</td>\n",
       "      <td>0.000652</td>\n",
       "      <td>...</td>\n",
       "      <td>0.998869</td>\n",
       "      <td>0.001846</td>\n",
       "      <td>0.998869</td>\n",
       "      <td>0.001126</td>\n",
       "      <td>3.683604</td>\n",
       "      <td>0.913672</td>\n",
       "      <td>0.005787</td>\n",
       "      <td>0.325286</td>\n",
       "      <td>0.007478</td>\n",
       "      <td>0.168214</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       PRECISION PRECISION_RECALL_MIN_DEN    RECALL      MAP MAP_MIN_DEN  \\\n",
       "cutoff                                                                     \n",
       "10      0.000208                 0.000209  0.000032  0.00007    0.000071   \n",
       "\n",
       "             MRR      NDCG        F1  HIT_RATE ARHR_ALL_HITS  ...  \\\n",
       "cutoff                                                        ...   \n",
       "10      0.000617  0.000103  0.000056  0.001848      0.000652  ...   \n",
       "\n",
       "       COVERAGE_USER COVERAGE_USER_HIT USERS_IN_GT DIVERSITY_GINI  \\\n",
       "cutoff                                                              \n",
       "10          0.998869          0.001846    0.998869       0.001126   \n",
       "\n",
       "       SHANNON_ENTROPY RATIO_DIVERSITY_HERFINDAHL RATIO_DIVERSITY_GINI  \\\n",
       "cutoff                                                                   \n",
       "10            3.683604                   0.913672             0.005787   \n",
       "\n",
       "       RATIO_SHANNON_ENTROPY RATIO_AVERAGE_POPULARITY RATIO_NOVELTY  \n",
       "cutoff                                                               \n",
       "10                  0.325286                 0.007478      0.168214  \n",
       "\n",
       "[1 rows x 27 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train and test type 2\n",
    "twotower_2 = TwoTowerRecommender_type2(URM_train, URM_train.shape[0], URM_train.shape[1], layers=[10,5,2,2], reg_layers=[0,0,0,0])\n",
    "\n",
    "twotower_2.fit(epochs=100, batch_size=1024, learning_rate=0.01)\n",
    "\n",
    "results_df, _ = evaluator_test.evaluateRecommender(twotower_2)\n",
    "\n",
    "results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Graph Convolution\n",
    "\n",
    "Graph Convolution methods combine the qualities of Graph-based models to the expressiveness of latent factor-based models. In this session, we will see a short synthesis of the main algorithms, LightGCN and GF-CF.\n",
    "\n",
    "To build a Graph Convolution method, we need 2 ingredients (plus, we need to decide whether to use self connections or not):\n",
    "1. A convolution (embedding aggregation) function\n",
    "2. A loss function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LightGCN\n",
    "\n",
    "LightGCN is a barebone, but very effective Graph Convolution recommender.\n",
    "\n",
    "1. Its convolution function is simply a weighted average (no self connections)\n",
    "2. It uses **BPR** as loss function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `computer()` method defines how to obtain the embedding matrix at step $h$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def computer(self):\n",
    "        \"\"\"\n",
    "        propagate methods for lightGCN\n",
    "        \"\"\"\n",
    "        users_emb = self.embedding_user.weight\n",
    "        items_emb = self.embedding_item.weight\n",
    "        all_emb = torch.cat([users_emb, items_emb])\n",
    "        embs = [all_emb]\n",
    "        if self.dropout_rate > 0.0:\n",
    "            if self.training:\n",
    "                g_dropped = self.__dropout(1 - self.dropout_rate)\n",
    "            else:\n",
    "                g_dropped = self.Graph\n",
    "        else:\n",
    "            g_dropped = self.Graph\n",
    "\n",
    "        for layer in range(self.n_layers): # <- n_layers = hops\n",
    "            all_emb = torch.sparse.mm(g_dropped, all_emb) # <- G * all_emb\n",
    "            embs.append(all_emb) # <- Collect results\n",
    "        embs = torch.stack(embs, dim=1)\n",
    "        light_out = torch.mean(embs, dim=1) # <- Aggregation\n",
    "        users, items = torch.split(light_out, [self.n_users, self.n_items])\n",
    "        return users, items"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `forward()` function uses `computer()` to get the embeddings, then computes predictions by multiplying user embeddings and item embeddings together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward(self, users, items):\n",
    "        # compute embedding\n",
    "        all_users, all_items = self.computer()\n",
    "        users_emb = all_users[users]\n",
    "        items_emb = all_items[items]\n",
    "        inner_pro = torch.mul(users_emb, items_emb)\n",
    "        gamma = torch.sum(inner_pro, dim=1)\n",
    "        return gamma"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GF-CF\n",
    "\n",
    "Graph Filter Collaborative Filtering is a Graph Convolution algorithm that combines simple item-based similarity recommendation to graph convolution. It imposes a \"high-pass filter\" over the adjacency matrix to select short-distance collaborative signals, ignoring those related to popularity.\n",
    "\n",
    "The model can be summarized by the following formula: $$S = \\hat{R^T} \\cdot \\hat{R} + \\alpha D_I^{-\\frac12}\\cdot V_K \\cdot V_K^T \\cdot D_I^{+\\frac12},$$ where $\\hat{R}$ is the L2-normalized URM, $D_I$ is the item degree diagonal matrix, and $V_K^T$ is the singular value matrix obtained from the URM using *Truncated SVD*. Just like $EASE^R$, it's very fast to compute (closed form solution), but very memory intensive. The following is its `fit()` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils.extmath import randomized_svd\n",
    "\n",
    "def fit(self, alpha=1.0, num_factors=50, random_seed = None):\n",
    "        self._print(\"Computing SVD decomposition of the normalized adjacency matrix...\")\n",
    "\n",
    "        self.alpha = alpha\n",
    "\n",
    "        self.D_I = np.sqrt(np.array(self.URM_train.sum(axis = 0))).squeeze()\n",
    "        self.D_I_inv = 1/(self.D_I + 1e-6)\n",
    "        self.D_U_inv = 1/np.sqrt(np.array(self.URM_train.sum(axis = 1))).squeeze() + 1e-6\n",
    "\n",
    "        self.D_I = sp.diags(self.D_I)\n",
    "        self.D_I_inv = sp.diags(self.D_I_inv)\n",
    "        self.D_U_inv = sp.diags(self.D_U_inv)\n",
    "\n",
    "        self.R_tilde = self.D_U_inv.dot(self.URM_train).dot(self.D_I_inv) # <- Normalized URM\n",
    "\n",
    "        _, _, self.V = randomized_svd(self.R_tilde,\n",
    "                                     n_components = num_factors,\n",
    "                                     random_state = random_seed) # <- Obtain V_K using truncated SVD\n",
    "\n",
    "        self.D_I = sp.csr_matrix(self.D_I)\n",
    "        self.D_I_inv = sp.csr_matrix(self.D_I_inv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `_compute_item_score()` method will then perform the aggregation of the components we thus obtained following the formula above. To avoid memory errors, matrix multiplications should be performed in blocks, as we have seen covering Graph-based models."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "RSFramework",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
